{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preprocessing",
   "id": "25c3af70ea5d6f26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T12:42:00.637215Z",
     "start_time": "2025-04-17T12:41:58.584787Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers 'nlu_intents.yml' et 'nlu_entities.yml' générés avec succès.\n"
     ]
    }
   ],
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Chargement et nettoyage\n",
    "# ----------------------------\n",
    "\n",
    "df = pd.read_csv('call_center_final.csv')\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\" #Vérifie si le texte est vide (NaN)\n",
    "    text = text.lower() #Met tout en minuscules\n",
    "    text = re.sub(r\"[^a-zàâäéèêëîïôöùûüç0-9\\s]\", \"\", text) # Supprime les caractères spéciaux sauf :lettres (accentuées incluses), chiffres, espaces\n",
    "    replacements = {\n",
    "        r\"\\bpr\\b\": \"pour\",\n",
    "        r\"\\bsvp\\b\": \"s'il vous plaît\",\n",
    "        r\"\\bjedis\\b\": \"je dis\",\n",
    "        r\"\\brathér\\b\": \"plutôt\",\n",
    "        r\"\\bdactions\\b\": \"d'actions\"\n",
    "    } # Remplace des abréviations ou mots fréquents\n",
    "    for pattern, replacement in replacements.items():\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "df['client_question_clean'] = df['client_question'].apply(clean_text)\n",
    "df['agent_response_clean'] = df['agent_response'].apply(clean_text)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Extraction des entités\n",
    "# ----------------------------\n",
    "# Elle sert à extraire des entités spécifiques (comme un RIB, numéro de compte ou nom/prénom) depuis une colonne d’un DataFrame.\n",
    "def extract_entities(row):\n",
    "    entities = []\n",
    "    text = row.get('client_responses', '')\n",
    "\n",
    "    if pd.isna(text):\n",
    "        return entities\n",
    "\n",
    "    for rib in re.findall(r\"\\b\\d{20}\\b\", text):\n",
    "        start = text.find(rib)\n",
    "        entities.append({\n",
    "            \"value\": rib,\n",
    "            \"entity\": \"rib\",\n",
    "            \"start\": start,\n",
    "            \"end\": start + len(rib)\n",
    "        })\n",
    "\n",
    "    for compte in re.findall(r\"\\b\\d{11}\\b\", text):\n",
    "        start = text.find(compte)\n",
    "        entities.append({\n",
    "            \"value\": compte,\n",
    "            \"entity\": \"num_compte\",\n",
    "            \"start\": start,\n",
    "            \"end\": start + len(compte)\n",
    "        })\n",
    "\n",
    "    name_match = re.search(r\"\\b([A-Z]+),\\s*([A-Z]+)\\b\", text)\n",
    "    if name_match:\n",
    "        nom = name_match.group(1)\n",
    "        prenom = name_match.group(2)\n",
    "        entities.append({\n",
    "            \"value\": nom,\n",
    "            \"entity\": \"nom_client\",\n",
    "            \"start\": name_match.start(1),\n",
    "            \"end\": name_match.end(1)\n",
    "        })\n",
    "        entities.append({\n",
    "            \"value\": prenom,\n",
    "            \"entity\": \"prenom_client\",\n",
    "            \"start\": name_match.start(2),\n",
    "            \"end\": name_match.end(2)\n",
    "        })\n",
    "\n",
    "    return entities\n",
    "\n",
    "df['entities'] = df.apply(extract_entities, axis=1)\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Mapping des intentions\n",
    "# ----------------------------\n",
    "# chaque intention exprimée naturellement est \"mappée\" (associée) à un code technique.\n",
    "\n",
    "intent_mapping = {\n",
    "    'Consultation du solde': 'consult_solde',\n",
    "    'Demande d\\'extrait de compte': 'demande_extrait',\n",
    "    'Consultation des dernières opérations': 'consult_operations',\n",
    "    'Consultation du nombre d’actions': 'consult_actions',\n",
    "    'Autre question bancaire': 'autre_question'\n",
    "}\n",
    "df['intent_mapped'] = df['motif'].map(intent_mapping).fillna(df['motif'])\n",
    "df = df.drop_duplicates(subset=['client_question_clean', 'intent_mapped'])\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Annotation des entités dans le texte\n",
    "# ----------------------------\n",
    "# Elle sert à annoter (marquer) dans un texte les entités détectées, en les entourant avec une notation spéciale\n",
    "\n",
    "def annotate_entities(text, entities):\n",
    "    if pd.isna(text) or not entities:\n",
    "        return text\n",
    "    annotated = text\n",
    "    for e in sorted(entities, key=lambda x: x['start'], reverse=True):\n",
    "        start, end = e['start'], e['end']\n",
    "        value = text[start:end]\n",
    "        annotated = f\"{annotated[:start]}[{value}]({e['entity']}){annotated[end:]}\"\n",
    "    return annotated\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Génération du fichier Rasa nlu.yml\n",
    "# ----------------------------\n",
    "\n",
    "def generate_rasa_nlu_file(df):\n",
    "    rasa_nlu_data = defaultdict(list)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        intent = row['intent_mapped']\n",
    "        question = row['client_question_clean']\n",
    "        entities = row.get('entities', [])\n",
    "        annotated_text = annotate_entities(question, entities)\n",
    "        if pd.notna(annotated_text):\n",
    "            rasa_nlu_data[intent].append(annotated_text)\n",
    "\n",
    "    with open(\"nlu.yml\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"version: \\\"3.1\\\"\\n\")\n",
    "        f.write(\"nlu:\\n\")\n",
    "        for intent, examples in rasa_nlu_data.items():\n",
    "            f.write(f\"- intent: {intent}\\n\")\n",
    "            f.write(\"  examples: |\\n\")\n",
    "            for ex in examples:\n",
    "                f.write(f\"    - {ex}\\n\")\n",
    "\n",
    "    print(\" Fichier 'nlu.yml' généré avec succès.\")\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Exécution\n",
    "# ----------------------------\n",
    "\n",
    "generate_rasa_nlu_file(df)\n"
   ],
   "id": "2086b045c3903350"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T11:31:18.636246Z",
     "start_time": "2025-05-26T11:31:18.440256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yaml\n",
    "\n",
    "# Chemin vers le fichier nlu.yml\n",
    "file_path = \"nlu2.yml\"\n",
    "\n",
    "# Chargement du fichier YAML\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = yaml.safe_load(f)\n",
    "\n",
    "# Dictionnaire pour stocker le nombre d'exemples par intention\n",
    "intent_counts = {}\n",
    "\n",
    "# Parcourir les données\n",
    "for nlu_entry in data.get(\"nlu\", []):\n",
    "    intent = nlu_entry.get(\"intent\")\n",
    "    examples = nlu_entry.get(\"examples\", \"\")\n",
    "    # Compter le nombre de lignes non vides après avoir enlevé le préfixe '-'\n",
    "    if intent and examples:\n",
    "        example_lines = [line.strip() for line in examples.strip().split('\\n') if line.strip().startswith(\"-\")]\n",
    "        intent_counts[intent] = len(example_lines)\n",
    "\n",
    "# Affichage des résultats\n",
    "for intent, count in intent_counts.items():\n",
    "    print(f\"Intention '{intent}': {count} exemples\")\n"
   ],
   "id": "e892824043d47862",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intention 'salutation': 26 exemples\n",
      "Intention 'consult_solde': 169 exemples\n",
      "Intention 'consult_actions': 109 exemples\n",
      "Intention 'demande_extrait': 96 exemples\n",
      "Intention 'consult_operations': 108 exemples\n",
      "Intention 'autre_question': 208 exemples\n",
      "Intention 'fournir_infos': 643 exemples\n",
      "Intention 'goodbye': 73 exemples\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Split train/test nlu2.yml",
   "id": "24bb7bcd2e1d2cf9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T14:27:52.455861Z",
     "start_time": "2025-04-23T14:27:50.824577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yaml\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Charger le fichier nlu.yml\n",
    "with open(\"nlu2.yml\", 'r', encoding='utf-8') as file:\n",
    "    data = yaml.safe_load(file)\n",
    "\n",
    "train_data = {\"version\": data.get(\"version\", \"3.1\"), \"nlu\": []}\n",
    "test_data = {\"version\": data.get(\"version\", \"3.1\"), \"nlu\": []}\n",
    "\n",
    "# Pour chaque intent, on divise les exemples\n",
    "for intent_block in data['nlu']:\n",
    "    intent_name = intent_block['intent']\n",
    "    examples = intent_block['examples'].strip().split('\\n')\n",
    "    examples = [ex.strip() for ex in examples if ex.strip()]\n",
    "\n",
    "    # Mélanger les exemples\n",
    "    random.shuffle(examples)\n",
    "\n",
    "    # Split 70% train, 30% test\n",
    "    split_idx = int(0.7 * len(examples))\n",
    "    train_examples = examples[:split_idx]\n",
    "    test_examples = examples[split_idx:]\n",
    "\n",
    "    # Ajouter au fichier train\n",
    "    if train_examples:\n",
    "        train_data['nlu'].append({\n",
    "            'intent': intent_name,\n",
    "            'examples': '\\n'.join(train_examples)\n",
    "        })\n",
    "\n",
    "    # Ajouter au fichier test\n",
    "    if test_examples:\n",
    "        test_data['nlu'].append({\n",
    "            'intent': intent_name,\n",
    "            'examples': '\\n'.join(test_examples)\n",
    "        })\n",
    "\n",
    "# Sauvegarder les fichiers\n",
    "with open(\"nlu2_train.yml\", 'w', encoding='utf-8') as train_file:\n",
    "    yaml.dump(train_data, train_file, allow_unicode=True, sort_keys=False)\n",
    "\n",
    "with open(\"nlu2_test.yml\", 'w', encoding='utf-8') as test_file:\n",
    "    yaml.dump(test_data, test_file, allow_unicode=True, sort_keys=False)\n",
    "\n",
    "print(\"Fichiers nlu22_train.yml et nlu22_test.yml générés avec succès.\")\n"
   ],
   "id": "196779b00c10d111",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers nlu2_train.yml et nlu2_test.yml générés avec succès.\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
